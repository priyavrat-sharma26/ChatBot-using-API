{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique intents:\n",
      "create_account\n",
      "delete_account\n",
      "edit_account\n",
      "recover_password\n",
      "registration_problems\n",
      "switch_account\n",
      "check_cancellation_fee\n",
      "contact_customer_service\n",
      "contact_human_agent\n",
      "delivery_options\n",
      "delivery_period\n",
      "complaint\n",
      "review\n",
      "check_invoices\n",
      "get_invoice\n",
      "newsletter_subscription\n",
      "cancel_order\n",
      "change_order\n",
      "place_order\n",
      "track_order\n",
      "check_payment_methods\n",
      "payment_issue\n",
      "check_refund_policy\n",
      "get_refund\n",
      "track_refund\n",
      "change_shipping_address\n",
      "set_up_shipping_address\n",
      "Intent Counts:\n",
      "intent\n",
      "payment_issue               4366\n",
      "create_account              2122\n",
      "contact_customer_service    2055\n",
      "get_invoice                 1430\n",
      "track_order                 1224\n",
      "get_refund                  1150\n",
      "contact_human_agent         1026\n",
      "check_invoices              1013\n",
      "recover_password             986\n",
      "change_order                 926\n",
      "delete_account               913\n",
      "complaint                    746\n",
      "review                       580\n",
      "check_refund_policy          479\n",
      "delivery_options             360\n",
      "check_cancellation_fee       360\n",
      "track_refund                 303\n",
      "switch_account               273\n",
      "check_payment_methods        270\n",
      "newsletter_subscription      236\n",
      "delivery_period              141\n",
      "edit_account                 133\n",
      "registration_problems        130\n",
      "change_shipping_address      110\n",
      "set_up_shipping_address       96\n",
      "place_order                   70\n",
      "cancel_order                  36\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21534"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# Load the CSV file\n",
    "file_path = \"../../resources/intent_detection/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample.csv\"  \n",
    "df = pd.read_csv(file_path)\n",
    " \n",
    "# Select only 'utterances' and 'intent' columns\n",
    "df = df[['utterance', 'intent']]\n",
    " \n",
    "# Check unique values in the 'intent' column\n",
    "unique_intents = df['intent'].unique()\n",
    "print(\"Unique intents:\")\n",
    "for intent in unique_intents:\n",
    "    print(intent)\n",
    " \n",
    "# Count occurrences of each unique intent\n",
    "intent_counts = df['intent'].value_counts()\n",
    " \n",
    "# Print the count for each unique intent\n",
    "print(\"Intent Counts:\")\n",
    "print(intent_counts)\n",
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn\n",
    " \n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode intents\n",
    "label_map = {intent: i for i, intent in enumerate(df['intent'].unique())}\n",
    "df['intent_label'] = df['intent'].map(label_map)\n",
    " \n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    " \n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and retaining labels\n",
    "def tokenize_and_preserve_labels(dataset):\n",
    "    tokenized_inputs = tokenizer(dataset['utterance'].tolist(), padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    tokenized_inputs['labels'] = torch.tensor(dataset['intent_label'].tolist())\n",
    "    return tokenized_inputs\n",
    " \n",
    "train_data_tokenized = tokenize_and_preserve_labels(train_data)\n",
    "test_data_tokenized = tokenize_and_preserve_labels(test_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        return item\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    " \n",
    "train_dataset = SimpleDataset(train_data_tokenized)\n",
    "test_dataset = SimpleDataset(test_data_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../../resources/intent_detection/Intent_detection_fine_tuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    " \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    " \n",
    " \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"../../resources/intent_detection/Intent_detection_fine_tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_intent(message):\n",
    "    inputs = tokenizer(message, return_tensors=\"pt\")\n",
    "    predictions = model(**inputs)\n",
    "    predicted_label = predictions.logits.argmax().item()\n",
    "    predicted_intent = [intent for intent, label in label_map.items() if label == predicted_label][0]\n",
    "    return predicted_intent\n",
    " \n",
    "# Test prediction\n",
    "new_message = \"Hi there is a problem. I have received damaged product. Can you cancel my order?\"\n",
    "predicted_intent = predict_intent(new_message)\n",
    "print(f\"Predicted intent for '{new_message}': {predicted_intent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
